{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.38.2)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/171.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/171.5 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/171.5 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 171.5/171.5 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers sentence-transformers numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained GPT-2 tokenizer and model\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b887f2bb4f5449f7aedce805ce0ec23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025f7ba3573a4e75b907cb3692f19154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57100fe05aba43da9b46817715814af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880b8c40e00d4cd5a2ed4afb57f1da45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f7b29b802c491a899cfc8936f2e7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96191e5bbbf2460fa5515b72ba829f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2479908b24d7a9b4ab138e3933415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4444a2c1c17044f98ca4c1eefcbcf4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35af5ca623d4443c8645e435f8d9c2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68e64b41ac74db59c13bb9c9e28620e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c9d7d7aa74407ba670d55cb070ce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the SentenceTransformer model for encoding documents\n",
    "sentence_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and build the FAISS index\n",
    "def build_index(documents):\n",
    "    document_embeddings = sentence_model.encode(documents, convert_to_tensor=True)\n",
    "    index = faiss.IndexFlatIP(document_embeddings.size(-1))\n",
    "    index.add(document_embeddings.numpy())\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(index, query, documents, k=3):\n",
    "    query_embedding = sentence_model.encode(query, convert_to_tensor=True)\n",
    "    if len(query_embedding.shape) == 2:  # Ensure query_embedding is 2-dimensional\n",
    "        D, I = index.search(query_embedding.numpy(), k)\n",
    "        print(\"Distances:\", D)\n",
    "        print(\"Indices:\", I)\n",
    "        if isinstance(D, np.ndarray) and isinstance(I, np.ndarray):\n",
    "            return [documents[i] for i in I[0]]\n",
    "    else:\n",
    "        print(\"Error: Query embedding shape is not as expected\")\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example retrieved documents (you'd replace this with actual retrieval logic)\n",
    "# Assume 'states.txt' contains documents about different states\n",
    "with open(\"states.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    documents = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the FAISS index\n",
    "index = build_index(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Query embedding shape is not as expected\n",
      "Generated Response:\n",
      "what is delhi?\n",
      "\n",
      "Delhi is a Sanskrit word meaning \"to be\" or \"in the presence of\". It is also used in the sense of \"the presence\" of a person or thing.\n",
      ". It means \"a person, thing, or object\".\n",
      " (Deli) is the Sanskrit term for \"thing\". The word is used to refer to a thing or a place. The term is often used as a synonym for a \"person\". (Dharma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Query embedding shape is not as expected\n",
      "Generated Response:\n",
      "what is mumbai called as?\n",
      "\n",
      "Mumbai is a city of people, people of colour, and people who are not afraid to speak their mind.\n",
      "...\n",
      ",\n",
      ":\n",
      "The people are the ones who speak the truth. The people speak truth because they are afraid of being misunderstood. They are scared of the people. And they speak it because it is their truth that they want to hear. It is the only way to be heard. If you are a person of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Query embedding shape is not as expected\n",
      "Generated Response:\n",
      "what is chennai?\n",
      "\n",
      "The answer is that the city is a city of the people.\n",
      "...\n",
      " (The people are the ones who are in charge of this city.)\n",
      ",\n",
      "- The people who live in the cities are called the \"people of God.\"\n",
      ": The city that is called \"the city\" is the one that has been created by God. The \"city\" that was created is God's city. God created the world. He created man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Query embedding shape is not as expected\n",
      "Generated Response:\n",
      "where is kolkata?\n",
      "\n",
      "Kolkat: I am not sure. I have not seen it.\n",
      " (Laughs)\n",
      "...\n",
      ",.,. (laughs)...\n",
      ":. I don't know. It's not like I'm going to go to the airport. But I will go. (Laughter) I'll go, I promise. And I won't go back. So I can't say anything. No, no, it's fine.\n"
     ]
    }
   ],
   "source": [
    "# Loop to take user queries until 'quit' is entered\n",
    "while True:\n",
    "    # Take user query\n",
    "    user_query = input(\"Please enter your question (type 'quit' to exit): \")\n",
    "    if user_query.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_documents = retrieve_documents(index, user_query, documents)\n",
    "\n",
    "    # Combine user query and retrieved documents\n",
    "    response = user_query + \"\\n\" + \"\\n\".join(retrieved_documents)\n",
    "\n",
    "    # Generate response using GPT-2 model\n",
    "    input_ids = tokenizer.encode(response, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "\n",
    "    # Decode and print the response\n",
    "    generated_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"Generated Response:\")\n",
    "    print(generated_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
